import streamlit as st
import pandas as pd
import numpy as np
import os
import glob
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

##############
# ëª¨ë“ˆí™” í•„ìš” #
################
# ë°ì´íƒ€ ë¶ˆëŸ¬ì˜¤ê¸°
rms_df=pd.read_csv("C:/Users/99kit/Desktop/CapstoneDesign_SmartFactory/"
                   "NASA_Bearing/2nd_test/RMS_Bearing.csv")
TrD=rms_df.values[0:400, :]                                                             #400í–‰*4ì—´
TsD=rms_df.values                                                                       #984í–‰*4ì—´
TrScore_arr=np.zeros([TrD.shape[0], TrD.shape[1]])                                      #np.zeros((400,4)) 1600ê°œì˜0ìœ¼ë¡œêµ¬ì„±
TsScore_arr=np.zeros([TsD.shape[0], TrD.shape[1]])                                      #np.zeros((984,4)) 3936ê°œì˜0ìœ¼ë¡œêµ¬ì„±

#MSET
lr=LinearRegression()
input_idx=np.arange(TrD.shape[1]).tolist()                                              #np.arange(4).tolist() [0,1,2,3]
for idx in input_idx:                                                                   #0
    input_idx=np.arange(TrD.shape[1]).tolist()                                          #[0,1,2,3]
    input_idx.remove(idx)                                                               #[1,2,3]
    lr.fit(TrD[:, input_idx], TrD[:, idx])                                              #x=TrD[:,[1,2,3]],y=TrD[:,0] í›ˆë ¨ë°ì´í„°ì—ì„œí•˜ë‚˜ì˜ë³€ìˆ˜ë¥¼ë‚˜ë¨¸ì§€ë³€ìˆ˜ì…‹ì˜ì„ í˜•ê²°í•©ìœ¼ë¡œí•™ìŠµ.ì¦‰,ê°€ì¤‘ì¹˜ë°ì ˆí¸í•™ìŠµ
    TrScore_arr[:, idx]=lr.predict(TrD[:, input_idx])                                   #í›ˆë ¨ë°ì´í„°ì˜ì„¸ë³€ìˆ˜ê°€ì£¼ì–´ì¡Œì„ë•Œyì—ëŒ€í•œì˜ˆì¸¡ê°’ ë³€ìˆ˜ë‹¹400ê°œì˜ì˜ˆì¸¡ê°’
    TsScore_arr[:, idx]=lr.predict(TsD[:, input_idx])                                   #ë³€ìˆ˜ë‹¹984ê°œì˜ì˜ˆì¸¡ê°’
TsScore_arr=pd.DataFrame(TsScore_arr, columns=['p_Ch 1', 'p_Ch 2', 'p_Ch 3', 'p_Ch 4'])

def bootlimit(stat, bootstrap, SigLev):                                         #bootstrapì€ì›ë³¸ë°ì´í„°ë¡œë¶€í„°BíšŒì˜ë³µì›ì¶”ì¶œì„í†µí•´Bê°œì˜ë°ì´í„°ì…‹ì„ì–»ëŠ”ë°©ë²•
    ConLev=100-SigLev*100                                                       #ConfidentialLevel=100-SignificanceLevel ì‹ ë¢°ìˆ˜ì¤€
    smplsz=len(stat)
    smpld_lmt=[]
    for i in range(bootstrap):
        smpld_lmt.append(np.percentile(np.random.choice(stat, smplsz), ConLev)) #statì—ì„œsmplszê°œì˜ìƒ˜í”Œì„ë³µì›ì¶”ì¶œ,í•´ë‹¹ë°ì´í„°ì˜ConLevë¶„ìœ„ìˆ˜ì¶”ì¶œ
    lmt=np.mean(smpld_lmt)                                                      #bootstrapê°œë°ì´í„°ì˜í‰ê· 
    return(lmt)

# Degradation Model
l2norm_TrScore=np.sqrt(np.sum(TrScore_arr**2, axis=1))      #norm=ë²¡í„°ì˜í¬ê¸°=ë²¡í„°ì˜ê¸¸ì´=ë²¡í„°ì˜ì‹œì‘ì ê³¼ëì ê±°ë¦¬=ë‘ë°ì´í„°ì˜ìœ ì‚¬ë„ë¥¼ë‚˜íƒ€ë‚´ëŠ”ì²™ë„
                                                            #L2Norm=EuclideanDistance ê°€ì¥ì§§ì€ì§ì„ ê±°ë¦¬
TrDegScore=np.cumsum(l2norm_TrScore)/np.arange(1, 401, 1)   
l2norm_TsScore=np.sqrt(np.sum(TsScore_arr**2, axis=1))
TsDegScore=np.cumsum(l2norm_TsScore)/np.arange(1, 985, 1)
cl_2=bootlimit(TrDegScore, SigLev=0.05, bootstrap=100)

yval2=np.full((984,), cl_2)
cmplx2=np.concatenate([TsDegScore, yval2], axis=0)
cmplx2=cmplx2.reshape(2, 984)
cmplx2=np.transpose(cmplx2)
##########################################

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_icon="ğŸ« ",
                   page_title="CBMforSmartFactory-RULPrediction",
                   layout="wide")
plt.rcParams['font.family']="NanumGothic"

# í˜ì´ì§€ í—¤ë”, ì„œë¸Œ í—¤ë” ì œëª© ì„¤ì •
st.header("RUL Prediction(ì”ì—¬ ìˆ˜ëª… ì˜ˆì¸¡)")

# í˜ì´ì§€ ì»¬ëŸ¼ ë¶„í• 
col1, col2 = st.columns([1, 2])

col1.write("ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ì”ì—¬ ìˆ˜ëª…ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
col1.write("ì´ë•Œ, ì‹œê³„ì—´ì„±ì„ ë°˜ì˜í•˜ë„ë¡ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.")

# exponential weight
def exponential_weight(length, alpha):
    exp_weight = []
    for i in range(1, length+1):
        w = alpha * (1-alpha)**i
        exp_weight.append(w)
    exp_weight = sorted(exp_weight, reverse=False)
    return(exp_weight)

# Exponentially Weighted Linear Regression
t=900
w=exponential_weight(length=t, alpha=0.05)

x=np.arange(t)
x=x.reshape(t, 1)
y=TsDegScore[0:t].values.reshape(t, 1)

EWLR = LinearRegression(fit_intercept=True)
EWLR.fit(x,y, sample_weight = w)

coef = EWLR.coef_
intercept = EWLR.intercept_

# predefined failure threshold
failure_threshold = max(TsDegScore)

# RUL Prediction Visualization
cl = bootlimit(TrDegScore, SigLev=0.05, bootstrap=100)

fig, ax = plt.subplots()

ax.plot(TsDegScore, color='blue', label='Test Data')
ax.set_xlim([0, 1200])
ax.set_ylim([min(TsDegScore), max(TsDegScore)*1.005])


x = np.arange(1400)
linear_curve = coef * x[:900] + intercept
linear_curve = np.concatenate([np.zeros(500), linear_curve])  # add zeros to match length of x
ax.plot(x, linear_curve, color='darkcyan', label='Exponentially Weighted Linear Regression')


# x = np.arange(1400)
# linear_curve = coef*x + intercept
# ax.plot(linear_curve[0], color='darkcyan', label='Exponentially Weighted Linear Regression')

ax.axhline(y=failure_threshold, color='red', label='Failure Threshold')
ax.axhline(y=cl, color='green', label='Confidence Limit')

ax.legend()

st.pyplot(fig)

# # Visualization of RUL Prediction
# cl = bootlimit(TrDegScore, SigLev=0.05, bootstrap=100)

# plt.plot(TsDegScore)

# plt.xlim([0, 1200])
# plt.ylim([min(TsDegScore), max(TsDegScore)*1.005])

# x = np.arange(1400)
# linear_curve = coef*x + intercept
# plt.plot(linear_curve[0], color='darkcyan')


###########################################
# Create a Matplotlib plot
fig, ax = plt.subplots()
ax.plot(x, y)

ax.axhline(y=failure_threshold, color='red')
ax.axhline(y=cl, color='red')

# Display the plot in Streamlit
st.pyplot(fig)
###########################################

# Result of RUL Prediction
predicted_failureTime= int((failure_threshold-intercept) / coef) # coefê°€ aë¼ê³  ë³´ë©´ ë¨í•„ê¸°í•œê±°ìˆì§€
RUL = predicted_failureTime-t

# print('ì˜ˆì¸¡ ì”ì—¬ì‹œì : %2.2fì‹œì ' % RUL)
# print('ì˜ˆì¸¡ ì”ì—¬ìˆ˜ëª…: %2.4fì¼' % (RUL*10/60/24))
# print()
# print('ì‹¤ì œ ì”ì—¬ì‹œì : %2.2fì‹œì ' % (984-t))
# print('ì‹¤ì œ ì”ì—¬ìˆ˜ëª…: %2.4fì¼' % ((984-t)*10/60/24))